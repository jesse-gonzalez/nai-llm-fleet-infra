k8s_cluster:

  ## kubernetes distribution - supported "nke" "kind"
  distribution: nke
  ## kubernetes cluster name
  name: _required
  ## cluster_profile_type - anything under clusters/_profiles (e.g., llm-management, llm-workloads, etc.)
  profile: _required
  ## environment name - based on profile selected under clusters/_profiles/<profile>/<environment> (e.g., prod, non-prod, etc.)
  environment: _required

  ## docker hub registry congis
  registry:
    docker_hub:
      user: _required
      password: _required

  ## nvidia gpu specific configs
  gpu_operator:
    enabled: false
    version: v23.9.0
   # cuda_toolkit_version: v1.14.3-centos7
   # time_slicing:
   #   enabled: false
   #   replica_count: 2

flux:
  ## flux specific configs for github repo
  github:
    repo_url: _required
    repo_user: _required
    repo_api_token: _required

infra:
  ## Global nutanix configs
  nutanix:
    ## Nutanix Prism Creds, required to download NKE creds
    prism_central:
      enabled: false
      # endpoint: _required
      # user: admin
      # password: _required

    ## Nutanix Objects Store Configs
    objects:
      enabled: false
      # host: _required
      # port: 80
      # region: us-east-1
      # use_ssl: true
      # access_key: _required
      # secret_key: _required

services:
  #####################################################
  ## Required variables for kube-vip and depedent services
  ## kube-vip specific configs required for any services needing to be configured with LoadBalancer Virtual IP Addresses
  kube_vip:
    enabled: false
    ## Used to configure default global IPAM pool. A minimum of 2 ips should be provide in a range
    ## For Example: ipam_range: 172.20.0.22-172.20.0.23
    #ipam_range: _required

  ## required for all platform services that are leveraging nginx-ingress
  nginx_ingress:
    enabled: false
    version: 4.8.3
    ## Virtual IP Address (VIP) dedicated for nginx-ingress controller. 
    ## This will be used to configure kube-vip IPAM pool to provide Services of Type: LoadBalancer
    ## Example: vip: 172.20.0.20
    #vip: _required
    
    ## NGINX Wildcard Ingress Subdomain used for all default ingress objects created within cluster 
    ## For DEMO purposes, it is common to prefix subdomain with cluster-name as each cluster would require dedicated wildcard domain.
    ## EXISTING A Host DNS Records are pre-requisites. Example: If DNS is equal to *.example.com, then value is example.com
    ## For DEMO purposes, you can leverage the NIP.IO with the nginx_ingress vip and self-signed certificates. 
    ## For Example: wildcard_ingress_subdomain:flux-kind-local.172.20.0.20.nip.io
    #wildcard_ingress_subdomain: _required

    ## Wildcard Ingress Subdomain for management cluster.
    ## For DEMO purposes, you can leverage the NIP.IO with the nginx_ingress vip and self-signed certificates
    #management_cluster_ingress_subdomain: _required


  istio:
    enabled: false
    version: 1.17.2
    ## Virtual IP Address (VIP) dedicated for istio ingress gateway. 
    ## This will be used to configure kube-vip IPAM pool to provide Services of Type: LoadBalancer
    ## This address should be mapped to wildcard_ingress_subdomain defined below. For Example: vip: 172.20.0.21
    #vip: _required

    ## Istio Ingress Gateway - Wildcard Subdomain used for all knative/kserve llm inference endpoints. 
    ## EXISTING A Host DNS Records are pre-requisites. Example: If DNS is equal to *.llm.example.com, then value is llm.example.com
    ## If leveraging AWS Route 53 DNS with Let's Encrypt (below), make sure to enable/configure AWS credentials needed to 
    ## support CertificateSigningRequests using ACME DNS Challenges.
    ## For DEMO purposes, you can leverage the NIP.IO with the nginx_ingress vip and self-signed certificates. 
    ## For Example: llm.flux-kind-local.172.20.0.21.nip.io
    #wildcard_ingress_subdomain: _required

  cert_manager:
    ## if enabled - cluster issuer will be self-signed-issuer
    enabled: false
    version: v1.3.0
    ## if aws_route53_acme_dns.enabled - the cluster issuer across all services will be set to "letsencrypt-issuer"
    ## Following AWS Route53 Access Creds required for Lets Encrypt ACME DNS Challenge
    aws_route53_acme_dns:
      enabled: false
      # zone: _required
      # region: us-east-2
      # key_id: _required
      # key_secret: _required

  # ## other platform config defaults. uncomment and override if needed
  # ## actual defaults stored in configs/_common/.env
  # kserve:
  #   version: v0.11.2
  # knative_serving:
  #   version: knative-v1.10.1
  # knative_istio:
  #   version: knative-v1.10.0
  # knative_eventing:
  #   version: knative-v1.10.1
  # kafka:
  #   version: 26.8.5
  # kubernetes_dashboard:
  #   version: 7.3.2
  # kyverno:
  #   version: 3.1.4
  # milvus:
  #   version: 4.1.13
  # opentelemetry_collector:
  #   version: 0.80.1
  # opentelemetry_operator:
  #   version: 0.47.0
  # uptrace:
  #   version: 1.5.7
  # weave_gitops:
  #   version: 4.0.36
  # jupyterhub:
  #   version: 3.1.0
  # redis:
  #   version: 18.1.6
  # elasticsearch:
  #   version: 19.13.10
apps:
  ## Required GPT NVD Reference Application Helm Chart Configs
  gptnvd_reference_app:
    enabled: false
    version: 0.2.7
    #milvus_bucket_name: milvus
    #documents_bucket_name: documents01
  ## Required NAI LLM Helm Chart Configs
  nai_helm:
    enabled: false
    version: 0.1.1
    #model: llama2_7b_chat
    #revision: 94b07a6e30c3292b8265ed32ffdeccfdadf434a8
    #maxTokens: 4000
    #repPenalty: 1.2
    #temperature: 0.2
    #topP: 0.9
    #useExistingNFS: false
    #nfs_export: /llm-model-store
    #nfs_server: _required
    #huggingFaceToken: xyzabc

  